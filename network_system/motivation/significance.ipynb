{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迭代过程中，significance的变化\n",
    "\n",
    "$|\\frac {t(n,i)-t(n-1)}{t(n-1)}|$ 在单机情况下, 退化为$|\\frac {t(n)-t(n-1)}{t(n-1)}|$\n",
    "\n",
    "$f(n,i)-f(n-1,i)-...-f(n-k,i),f(n,i)=|\\frac {t(n,i)-t(n-1)}{t(n-1)}|,k表示要向前考虑的迭代轮数，是一个超参数$退化为$f(n)-f(n-1)-...-f(n-k),f(n)=|\\frac {t(n)-t(n-1)}{t(n-1)}|,k表示要向前考虑的迭代轮数，是一个超参数$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练过程是用CNN训练FEMNIST(新数据集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import random\n",
    "import numpy as np\n",
    "from d2l import torch as d2l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通用函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(net_1,net_2):\n",
    "    \"\"\"\n",
    "        输入更新前后的网络f(n) f(n-1)\n",
    "        对各个参数应用 (w(n)-w(n-1))/w(n-1), 最后加权平均\n",
    "    \"\"\"\n",
    "    net_1.parameters()\n",
    "    net_2.parameters()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgCNN(nn.Module):\n",
    "    def __init__(self,dropout=0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(1,32,(5,5))\n",
    "        self.max_pool = nn.MaxPool2d((2,2))\n",
    "        self.conv2d_2 = nn.Conv2d(32,64,(5,5))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(1024,512)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.linear = nn.Linear(512,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv2d_1(x) # 32,24,24\n",
    "        x = self.relu(x) # 32,24,24\n",
    "        x = self.max_pool(x) # 32,12,12\n",
    "\n",
    "        x = self.conv2d_2(x) # 32,12,12\n",
    "        x = self.relu(x) # 32,12,12\n",
    "        x = self.max_pool(x) # 32,6,6\n",
    "\n",
    "        x = self.flat(x) # 1152\n",
    "        x = self.fc(x) # 512\n",
    "        x = self.relu(x) # 512\n",
    "        x = self.dropout(x) # 512\n",
    "\n",
    "        x = self.softmax(x) # 512\n",
    "\n",
    "        x = self.linear(x) # 10\n",
    "\n",
    "        return x\n",
    "\n",
    "    def init_params(self, seed):\n",
    "        set_seed(seed)\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                # 参数初始化方法一般与激活函数有关\n",
    "                # Relu-kaming\n",
    "                # sigmoid-xavier\n",
    "                nn.init.kaiming_normal_(layer.weight.data)\n",
    "                nn.init.zeros_(layer.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "lr = 1e-3\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = FedAvgCNN()\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(cnn.parameters(),lr=lr,momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,test_dataloader = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animator = d2l.Animator('iter',['train_loss','train_acc','test_acc'])\n",
    "\n",
    "for e in range(epoch):\n",
    "    cnn.train()\n",
    "\n",
    "    inner_accum = d2l.Accumulator(3)\n",
    "    for x,y in train_dataloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = cnn(y)\n",
    "        loss = loss_func(y_hat,y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        train_acc = d2l.accuracy(y_hat,y)\n",
    "        n = len(x)\n",
    "        inner_accum.add(loss*n,train_acc*n,n)\n",
    "\n",
    "    cnn.eval()\n",
    "    test_acc = d2l.evaluate_accuracy_gpu(cnn,test_dataloader,device)\n",
    "    animator.add(inner_accum[0]/inner_accum[-1],inner_accum[1]/inner_accum[-1],test_acc)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
