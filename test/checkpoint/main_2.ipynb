{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=0):\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class NotAbsPathException(Exception):\n",
    "    def __init__(self,path, *args: object) -> None:\n",
    "        super().__init__(*args)\n",
    "        self.path = path\n",
    "    def __str__(self):\n",
    "        return f\"{self.path} is not an abstract path\"\n",
    "\n",
    "class CheckPoint:\n",
    "    def __init__(self,path,file_name) -> None:\n",
    "        \"\"\"\n",
    "            检查path是否是绝对路径\n",
    "            检查多级目录是否创建\n",
    "        \"\"\"\n",
    "        if not os.path.isabs(path):\n",
    "            raise NotAbsPathException(path)\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        self.path = path\n",
    "        self.file_name = file_name\n",
    "        self.file_path = os.path.join(self.path,self.file_name)\n",
    "\n",
    "    def save(self,data:dict):\n",
    "        \"\"\"\n",
    "            保存数据, 所有数据完全由用户提供(不同情况下, 需要保存的数据不同, 没有相同的解决方案)\n",
    "        \"\"\"\n",
    "        torch.save(data,self.file_path)\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "            加载\n",
    "        \"\"\"\n",
    "        return torch.load(self.file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MNIST_2NN(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # 输入：784\n",
    "        # 隐藏层 1：784*200，200\n",
    "        # 隐藏层 2：200*200，200\n",
    "        # 输出：200*10,10\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.fc_1 = torch.nn.Linear(784, 200)\n",
    "        self.fc_2 = torch.nn.Linear(200, 200)\n",
    "        self.fc_3 = torch.nn.Linear(200, 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def init_params(self, seed):\n",
    "        set_seed(seed)\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                # 参数初始化方法一般与激活函数有关\n",
    "                # Relu-kaming\n",
    "                # sigmoid-xavier\n",
    "                torch.nn.init.kaiming_normal_(layer.weight.data)\n",
    "                torch.nn.init.zeros_(layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.nn.Dropout(0.5)(x)  # 过拟合\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = torch.nn.Dropout(0.5)(x)  # 过拟合\n",
    "        x = self.fc_3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reload_flag = True # 是否从目录重新加载\n",
    "log_dir = '/home/whr-pc-ubuntu/code/test/checkpoint/log/1111'\n",
    "file_name = 'models.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "net = MNIST_2NN()\n",
    "net.init_params(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = CheckPoint(log_dir,file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint.save({\n",
    "    \"model\":net.state_dict(),\n",
    "    \"step\":0\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OrderedDict([('fc_1.weight',\n",
       "               tensor([[-0.0569, -0.0582, -0.0127,  ..., -0.0799, -0.0297, -0.0058],\n",
       "                       [ 0.0354, -0.0281, -0.0193,  ...,  0.0201,  0.0130,  0.0101],\n",
       "                       [-0.0080,  0.0373, -0.0127,  ...,  0.0465, -0.0056, -0.0946],\n",
       "                       ...,\n",
       "                       [ 0.0469, -0.0082,  0.0193,  ...,  0.0332, -0.0398, -0.0023],\n",
       "                       [-0.0562,  0.0057, -0.0071,  ...,  0.0176,  0.0732, -0.1302],\n",
       "                       [-0.0638,  0.1276, -0.0920,  ..., -0.0135, -0.0364, -0.1337]])),\n",
       "              ('fc_1.bias',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "              ('fc_2.weight',\n",
       "               tensor([[-0.0722, -0.1315, -0.0226,  ..., -0.2176, -0.1793, -0.0266],\n",
       "                       [ 0.0985,  0.1414, -0.1288,  ..., -0.0294,  0.0418, -0.0042],\n",
       "                       [ 0.1272,  0.0326, -0.0473,  ...,  0.2009, -0.1764, -0.0042],\n",
       "                       ...,\n",
       "                       [ 0.0343, -0.2126,  0.0922,  ..., -0.0645, -0.0035, -0.0794],\n",
       "                       [ 0.1270, -0.0605, -0.0718,  ..., -0.0172, -0.0517,  0.0251],\n",
       "                       [-0.0205, -0.0162, -0.0770,  ..., -0.0911, -0.0793, -0.0390]])),\n",
       "              ('fc_2.bias',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                       0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "              ('fc_3.weight',\n",
       "               tensor([[ 0.1754, -0.1504, -0.0906,  ..., -0.1142, -0.0552, -0.1355],\n",
       "                       [-0.0829,  0.1394, -0.1570,  ...,  0.1232,  0.2199,  0.0552],\n",
       "                       [ 0.0927,  0.0787, -0.0635,  ..., -0.0886, -0.1091,  0.1068],\n",
       "                       ...,\n",
       "                       [-0.0377,  0.2080, -0.0109,  ...,  0.0010, -0.1019, -0.1310],\n",
       "                       [-0.2304,  0.1669,  0.0563,  ..., -0.0197,  0.0079,  0.1777],\n",
       "                       [-0.1246, -0.0543,  0.0702,  ...,  0.0316,  0.0400, -0.0978]])),\n",
       "              ('fc_3.bias',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))]),\n",
       " 'step': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "reload_flag = False # 是否从目录重新加载\n",
    "log_dir = '/home/whr-pc-ubuntu/code/test/checkpoint/log/1111'\n",
    "file_name = 'models.pth'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test\n",
    "\n",
    "先训练一段时间, 将结果记录在tensor board中\n",
    "\n",
    "然后将reload_flag修改为True, 观察tensor board的曲线是否是连贯的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def now_str():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "\n",
    "def get_writer(*tags):\n",
    "    path = 'logs'\n",
    "    for tag in tags:\n",
    "        path = join(path, tag)\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    return writer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(seed=0, batch_size=256, shuffle=True):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081)),\n",
    "    ])\n",
    "    dataset_path = '/home/whr-pc-ubuntu/code/dataset'\n",
    "\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        dataset_path,\n",
    "        True,\n",
    "        transform,\n",
    "        download=True,\n",
    "    )\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        dataset_path,\n",
    "        False,\n",
    "        transform,\n",
    "        download=True,\n",
    "    )\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle)\n",
    "\n",
    "    return train_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "load_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "seed = 0\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "train_dataloader,test_dataloader = load_data(seed,batch_size,False)\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = '/home/whr-pc-ubuntu/code/test/checkpoint/log/2222'\n",
    "file_name = 'models.pth'\n",
    "checkpoint = CheckPoint(log_dir,file_name)\n",
    "writer = get_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "net = MNIST_2NN()\n",
    "net.init_params(seed)\n",
    "net.to(device)\n",
    "optim = torch.optim.SGD(net.parameters(),lr)    \n",
    "start = 0\n",
    "\n",
    "if load_flag:\n",
    "    data = checkpoint.load()\n",
    "    net.load_state_dict(data['model'])\n",
    "    optim.load_state_dict(data['optim'])\n",
    "    start = data['i'] + 1\n",
    "    \n",
    "net.eval()    \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "accumulator = d2l.Accumulator(3)\n",
    "for i in range(start,epoch):\n",
    "    for x,y in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_hat = net(x)\n",
    "\n",
    "        loss = loss_func(y_hat,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "\n",
    "    test_acc = d2l.evaluate_accuracy_gpu(net,test_dataloader,device)\n",
    "\n",
    "    writer.add_scalar(\"train loss\",accumulator[0]/accumulator[-1],i)\n",
    "    writer.add_scalar(\"train acc\",accumulator[1]/accumulator[-1],i)\n",
    "    writer.add_scalar(\"test acc\",test_acc,i)\n",
    "    \n",
    "    \n",
    "    # 间隔20次保存一次\n",
    "    if i%20 == 0:\n",
    "        checkpoint.save({\n",
    "            \"model\":net.state_dict(),\n",
    "            \"optim\":optim.state_dict(),\n",
    "            \"i\":i\n",
    "            })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "load_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "seed = 0\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "train_dataloader,test_dataloader = load_data(seed,batch_size,False)\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = '/home/whr-pc-ubuntu/code/test/checkpoint/log/2222'\n",
    "file_name = 'models.pth'\n",
    "checkpoint = CheckPoint(log_dir,file_name)\n",
    "writer = get_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reload\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/test/checkpoint/main.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/test/checkpoint/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m accumulator \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mAccumulator(\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/test/checkpoint/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start,epoch):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/test/checkpoint/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/test/checkpoint/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/test/checkpoint/main.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         x,y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device),y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39;49mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = MNIST_2NN()\n",
    "net.init_params(seed)\n",
    "net.to(device)\n",
    "optim = torch.optim.SGD(net.parameters(),lr)    \n",
    "start = 0\n",
    "\n",
    "if load_flag:\n",
    "    print(\"reload\")\n",
    "    data = checkpoint.load()\n",
    "    net.load_state_dict(data['model'])\n",
    "    optim.load_state_dict(data['optim'])\n",
    "    start = data['i'] + 1\n",
    "\n",
    "net.eval()    \n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "accumulator = d2l.Accumulator(3)\n",
    "for i in range(start,epoch):\n",
    "    for x,y in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_hat = net(x)\n",
    "\n",
    "        loss = loss_func(y_hat,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "\n",
    "    writer.add_scalar(\"train loss\",accumulator[0]/accumulator[-1],i)\n",
    "    writer.add_scalar(\"train acc\",accumulator[1]/accumulator[-1],i)\n",
    "    \n",
    "    # 间隔20次保存一次\n",
    "    if i%20 == 0:\n",
    "        checkpoint.save({\n",
    "            \"model\":net.state_dict(),\n",
    "            \"optim\":optim.state_dict(),\n",
    "            \"i\":i\n",
    "            })\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epoch等效替代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 40\n",
    "seed = 0\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "train_dataloader,test_dataloader = load_data(seed,batch_size,False)\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = '/home/whr-pc-ubuntu/code/test/checkpoint/log/3333'\n",
    "file_name = 'models.pth'\n",
    "checkpoint = CheckPoint(log_dir,file_name)\n",
    "writer = get_writer(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "net = MNIST_2NN()\n",
    "net.init_params(seed)\n",
    "net.to(device)\n",
    "optim = torch.optim.SGD(net.parameters(),lr)    \n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "accumulator = d2l.Accumulator(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,epoch):\n",
    "    for x,y in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_hat = net(x)\n",
    "\n",
    "        loss = loss_func(y_hat,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "\n",
    "    writer.add_scalar(\"train loss\",accumulator[0]/accumulator[-1],i)\n",
    "    writer.add_scalar(\"train acc\",accumulator[1]/accumulator[-1],i)\n",
    "    \n",
    "    # 间隔20次保存一次\n",
    "    if i%20 == 0:\n",
    "        checkpoint.save({\n",
    "            \"model\":net.state_dict(),\n",
    "            \"optim\":optim.state_dict(),\n",
    "            \"i\":i\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(epoch,2*epoch):\n",
    "    for x,y in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_hat = net(x)\n",
    "\n",
    "        loss = loss_func(y_hat,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "\n",
    "    writer.add_scalar(\"train loss\",accumulator[0]/accumulator[-1],i)\n",
    "    writer.add_scalar(\"train acc\",accumulator[1]/accumulator[-1],i)\n",
    "    \n",
    "    # 间隔20次保存一次\n",
    "    if i%20 == 0:\n",
    "        checkpoint.save({\n",
    "            \"model\":net.state_dict(),\n",
    "            \"optim\":optim.state_dict(),\n",
    "            \"i\":i\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,epoch):\n",
    "    for x,y in train_dataloader:\n",
    "        optim.zero_grad()\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_hat = net(x)\n",
    "\n",
    "        loss = loss_func(y_hat,y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "\n",
    "    writer.add_scalar(\"train loss\",accumulator[0]/accumulator[-1],i)\n",
    "    writer.add_scalar(\"train acc\",accumulator[1]/accumulator[-1],i)\n",
    "    \n",
    "    # 间隔20次保存一次\n",
    "    if i%20 == 0:\n",
    "        checkpoint.save({\n",
    "            \"model\":net.state_dict(),\n",
    "            \"optim\":optim.state_dict(),\n",
    "            \"i\":i\n",
    "            })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
