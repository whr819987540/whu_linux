{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchsummary\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n",
    "\n",
    "MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "    dataset_path = \"/home/whr-pc-ubuntu/code/dataset\"\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path,True,transform,download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path,False,transform,download=True)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size,shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset,batch_size,shuffle=True)\n",
    "\n",
    "    return train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,test_dataloader = load_data(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 8, 8, 7, 8, 0, 0, 5, 6, 0, 0, 3, 5, 8, 1, 6, 2, 4, 1, 4, 9, 4, 3, 4,\n",
       "        1, 4, 8, 7, 6, 3, 1, 8, 4, 4, 6, 2, 4, 2, 9, 5, 7, 8, 0, 7, 5, 5, 9, 3,\n",
       "        6, 6, 4, 6, 7, 8, 3, 6, 2, 2, 7, 7, 2, 4, 4, 9, 9, 5, 2, 2, 9, 0, 9, 4,\n",
       "        6, 5, 8, 5, 7, 1, 4, 2, 1, 8, 8, 6, 9, 7, 8, 0, 0, 8, 8, 6, 5, 0, 6, 9,\n",
       "        7, 4, 1, 8, 1, 4, 0, 3, 5, 4, 6, 8, 1, 8, 7, 5, 5, 6, 0, 6, 5, 4, 9, 2,\n",
       "        6, 0, 3, 1, 5, 8, 4, 0, 0, 9, 2, 5, 1, 1, 1, 8, 7, 7, 8, 0, 9, 2, 6, 4,\n",
       "        3, 9, 0, 5, 4, 5, 9, 8, 4, 8, 4, 6, 3, 1, 2, 3, 2, 6, 5, 2, 1, 8, 7, 3,\n",
       "        0, 8, 5, 6, 2, 2, 1, 8, 6, 3, 9, 5, 6, 9, 0, 2, 0, 9, 7, 5, 9, 4, 7, 2,\n",
       "        6, 0, 3, 8, 7, 5, 8, 9, 6, 3, 4, 5, 9, 4, 8, 1, 7, 9, 9, 0, 4, 8, 7, 7,\n",
       "        0, 3, 9, 3, 3, 8, 1, 7, 7, 9, 9, 1, 1, 8, 0, 3, 3, 7, 3, 5, 1, 6, 8, 9,\n",
       "        8, 3, 5, 0, 5, 6, 7, 6, 7, 1, 3, 1, 7, 1, 4, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获得batch时再设置seed，否则每次训练时seed还是不一样\n",
    "set_seed(0)\n",
    "next(iter(train_dataloader))[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedAvgCNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(1,32,(5,5))\n",
    "        self.max_pool = nn.MaxPool2d((2,2))\n",
    "        self.conv2d_2 = nn.Conv2d(32,64,(5,5))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(1024,512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.linear = nn.Linear(512,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        start = time.time()\n",
    "        x = self.conv2d_1(x) # 32,24,24\n",
    "        end = time.time()\n",
    "        print('conv2d_1',end-start)\n",
    "        \n",
    "        x = self.relu(x) # 32,24,24\n",
    "        x = self.max_pool(x) # 32,12,12\n",
    "\n",
    "        start = time.time()\n",
    "        x = self.conv2d_2(x) # 32,12,12\n",
    "        end = time.time()\n",
    "        print('conv2d_2',end-start)\n",
    "        \n",
    "        x = self.relu(x) # 32,12,12\n",
    "        x = self.max_pool(x) # 32,6,6\n",
    "\n",
    "\n",
    "        x = self.flat(x) # 1152\n",
    "\n",
    "        start = time.time()\n",
    "        x = self.fc(x) # 512\n",
    "        end = time.time()\n",
    "        print('fc',end-start)\n",
    "        \n",
    "        x = self.relu(x) # 512\n",
    "        x = nn.Dropout(0.5)(x) # 512\n",
    "\n",
    "        x = self.softmax(x) # 512\n",
    "\n",
    "        x = self.linear(x) # 10\n",
    "\n",
    "        return x\n",
    "\n",
    "    # def forward(self,x):\n",
    "    #     x = self.conv2d_1(x) # 32,24,24\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.relu(x) # 32,24,24\n",
    "    #     print(x.shape)\n",
    "        \n",
    "    #     x = self.max_pool(x) # 32,12,12\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.conv2d_2(x) # 64,8,8\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.relu(x) # 64,8,8\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.max_pool(x) # 64,4,4\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.flat(x) # 1024\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.fc(x) # 512\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.relu(x) # 512\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = nn.Dropout(0.5)(x) # 512\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.softmax(x) # 512\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     x = self.linear(x) # 10\n",
    "    #     print(x.shape)\n",
    "\n",
    "    #     return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = FedAvgCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1 0.0033109188079833984\n",
      "conv2d_2 0.005147218704223633\n",
      "fc 0.0010139942169189453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358369/236861498.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x) # 512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0031,  0.0266, -0.0212,  ..., -0.0124,  0.0224, -0.0129],\n",
       "        [ 0.0032,  0.0266, -0.0211,  ..., -0.0124,  0.0224, -0.0129],\n",
       "        [ 0.0031,  0.0266, -0.0212,  ..., -0.0126,  0.0223, -0.0127],\n",
       "        ...,\n",
       "        [ 0.0030,  0.0266, -0.0211,  ..., -0.0125,  0.0224, -0.0128],\n",
       "        [ 0.0031,  0.0266, -0.0212,  ..., -0.0126,  0.0222, -0.0127],\n",
       "        [ 0.0031,  0.0267, -0.0211,  ..., -0.0126,  0.0223, -0.0127]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(next(iter(train_dataloader))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = FedAvgCNN()\n",
    "cnn = cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_dataloader))[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1 0.0004572868347167969\n",
      "conv2d_2 0.00012993812561035156\n",
      "fc 8.463859558105469e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_358369/236861498.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x) # 512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0263, -0.0118,  0.0006,  ...,  0.0289,  0.0086,  0.0117],\n",
       "        [-0.0260, -0.0118,  0.0005,  ...,  0.0287,  0.0087,  0.0118],\n",
       "        [-0.0260, -0.0118,  0.0006,  ...,  0.0286,  0.0085,  0.0119],\n",
       "        ...,\n",
       "        [-0.0260, -0.0119,  0.0007,  ...,  0.0287,  0.0087,  0.0120],\n",
       "        [-0.0263, -0.0118,  0.0007,  ...,  0.0287,  0.0086,  0.0119],\n",
       "        [-0.0261, -0.0119,  0.0007,  ...,  0.0287,  0.0087,  0.0118]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            832\n",
      "├─MaxPool2d: 1-2                         --\n",
      "├─Conv2d: 1-3                            51,264\n",
      "├─Flatten: 1-4                           --\n",
      "├─Linear: 1-5                            524,800\n",
      "├─ReLU: 1-6                              --\n",
      "├─Softmax: 1-7                           --\n",
      "├─Linear: 1-8                            5,130\n",
      "=================================================================\n",
      "Total params: 582,026\n",
      "Trainable params: 582,026\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Conv2d: 1-1                            832\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            51,264\n",
       "├─Flatten: 1-4                           --\n",
       "├─Linear: 1-5                            524,800\n",
       "├─ReLU: 1-6                              --\n",
       "├─Softmax: 1-7                           --\n",
       "├─Linear: 1-8                            5,130\n",
       "=================================================================\n",
       "Total params: 582,026\n",
       "Trainable params: 582,026\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchsummary.summary(cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
