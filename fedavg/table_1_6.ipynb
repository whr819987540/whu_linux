{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchsummary\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_number = 100\n",
    "seed = 0\n",
    "B = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_IID(client_number, seed):\n",
    "    # shuffle,fix the seed\n",
    "    # 100 clients, each 100 examples\n",
    "    dataset_path = \"/home/whr-pc-ubuntu/code/dataset\"\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081)), # 归一化，有利于训练\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path, True, transform, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path, False, transform, download=True)\n",
    "\n",
    "    slice_num = int(len(train_dataset) / client_number)\n",
    "    split_list = [slice_num]*(client_number-1)\n",
    "    split_list.append(len(train_dataset)-sum(split_list))\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_datasets = random_split(train_dataset, split_list)\n",
    "\n",
    "    return train_datasets, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_IID(client_number, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "4\n",
      "0\n",
      "6\n",
      "8\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "1\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "1\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "2\n",
      "1\n",
      "0\n",
      "7\n",
      "9\n",
      "2\n",
      "6\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "1\n",
      "9\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "6\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "8\n",
      "5\n",
      "0\n",
      "2\n",
      "7\n",
      "2\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "0\n",
      "2\n",
      "9\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "1\n",
      "8\n",
      "8\n",
      "7\n",
      "6\n",
      "2\n",
      "0\n",
      "7\n",
      "3\n",
      "9\n",
      "2\n",
      "1\n",
      "4\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "0\n",
      "7\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "9\n",
      "7\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "4\n",
      "7\n",
      "7\n",
      "2\n",
      "8\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "8\n",
      "9\n",
      "9\n",
      "7\n",
      "6\n",
      "3\n",
      "9\n",
      "3\n",
      "4\n",
      "0\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "9\n",
      "1\n",
      "6\n",
      "4\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "8\n",
      "8\n",
      "9\n",
      "6\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "1\n",
      "7\n",
      "8\n",
      "7\n",
      "2\n",
      "1\n",
      "4\n",
      "6\n",
      "1\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "9\n",
      "3\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "7\n",
      "2\n",
      "8\n",
      "1\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "7\n",
      "0\n",
      "8\n",
      "7\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "5\n",
      "7\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "8\n",
      "0\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "9\n",
      "7\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "8\n",
      "7\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "2\n",
      "8\n",
      "1\n",
      "2\n",
      "7\n",
      "3\n",
      "5\n",
      "9\n",
      "1\n",
      "8\n",
      "2\n",
      "5\n",
      "8\n",
      "5\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "8\n",
      "3\n",
      "6\n",
      "9\n",
      "8\n",
      "2\n",
      "0\n",
      "9\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "9\n",
      "6\n",
      "1\n",
      "5\n",
      "8\n",
      "1\n",
      "7\n",
      "3\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "5\n",
      "0\n",
      "9\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "9\n",
      "3\n",
      "3\n",
      "7\n",
      "9\n",
      "2\n",
      "4\n",
      "3\n",
      "8\n",
      "8\n",
      "1\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "9\n",
      "0\n",
      "3\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "9\n",
      "3\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "9\n",
      "0\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "3\n",
      "8\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "5\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "7\n",
      "9\n",
      "9\n",
      "0\n",
      "0\n",
      "7\n",
      "4\n",
      "3\n",
      "9\n",
      "7\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "1\n",
      "7\n",
      "0\n",
      "2\n",
      "9\n",
      "1\n",
      "1\n",
      "7\n",
      "7\n",
      "0\n",
      "1\n",
      "9\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "9\n",
      "3\n",
      "4\n",
      "0\n",
      "7\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "5\n",
      "9\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "9\n",
      "4\n",
      "4\n",
      "3\n",
      "7\n",
      "0\n",
      "9\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "6\n",
      "6\n",
      "9\n",
      "4\n",
      "0\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "5\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "9\n",
      "4\n",
      "2\n",
      "9\n",
      "6\n",
      "1\n",
      "8\n",
      "1\n",
      "3\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "1\n",
      "4\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "9\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "4\n",
      "8\n",
      "5\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in train_datasets[0]:\n",
    "    print(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_Non_IDD(client_number):\n",
    "    # short by digit label, ascending\n",
    "    # 200 shards, each 300 examples\n",
    "    # 100 clients, each 2 shards\n",
    "    # that is, 100 clients, each 600 examples\n",
    "    dataset_path = \"/home/whr-pc-ubuntu/code/dataset\"\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path, True, transform, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path, False, transform, download=True)\n",
    "\n",
    "    # before = [i[1]for i in train_dataset]\n",
    "    # print(before)\n",
    "    train_dataset = sorted(train_dataset, key=lambda x: x[1])\n",
    "    # after = [i[1] for i in train_dataset]\n",
    "    # print(after)\n",
    "\n",
    "    slice_num = int(len(train_dataset) / client_number)\n",
    "    train_datasets = []\n",
    "    for i in range(client_number-1):\n",
    "        train_datasets.append(train_dataset[i*slice_num:(i+1)*slice_num])\n",
    "    train_datasets.append(train_dataset[(client_number-1)*slice_num:])\n",
    "\n",
    "    return train_datasets, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_Non_IDD(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in train_datasets[0]:\n",
    "    print(i[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST_2NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_2NN(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # 输入：784\n",
    "        # 隐藏层 1：784*200，200\n",
    "        # 隐藏层 2：200*200，200\n",
    "        # 输出：200*10,10\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.fc_1 = torch.nn.Linear(784, 200)\n",
    "        self.fc_2 = torch.nn.Linear(200, 200)\n",
    "        self.fc_3 = torch.nn.Linear(200, 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def init_params(self, seed):\n",
    "        set_seed(seed)\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                # 参数初始化方法一般与激活函数有关\n",
    "                # Relu-kaming\n",
    "                # sigmoid-xavier\n",
    "                nn.init.kaiming_normal_(layer.weight.data)\n",
    "                nn.init.zeros_(layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = nn.Dropout(0.5)(x)  # 过拟合\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = nn.Dropout(0.5)(x)  # 过拟合\n",
    "        x = self.fc_3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_global_net(global_net, local_net, global_num, local_num):\n",
    "    index = 1.0 * local_num / global_num\n",
    "    optim_1 = torch.optim.SGD(global_net.parameters(), 0.1)  # whatever the lr is\n",
    "    optim_2 = torch.optim.SGD(local_net.parameters(), 0.1)  # whatever the lr is\n",
    "\n",
    "    for param_1, param_2 in zip(optim_1.param_groups[0]['params'], optim_2.param_groups[0]['params']):\n",
    "        param_1.data = param_1.data + index * param_2.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_net_zero(global_net):\n",
    "    optim = torch.optim.SGD(global_net.parameters(), 0.1)  # whatever the lr is\n",
    "\n",
    "    for param in optim.param_groups[0]['params']:\n",
    "        param.data.zero_()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算 test acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_acc(net,test_dataloader,device=torch.device(\"cpu:0\")):\n",
    "    with torch.no_grad():\n",
    "        sum = 0\n",
    "        for x,y in test_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_hat = net(x)\n",
    "            sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "    return 1.0 * sum / len(test_dataset)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0954"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MNIST_2NN()\n",
    "net.init_params(seed)\n",
    "get_test_acc(net, test_dataloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST_2NN exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0  # to initialize the global net\n",
    "E = 1  # epoch\n",
    "client_number = 100  # client_number\n",
    "C_list = [0, 0.1, 0.2, 0.5, 1.0]  # m=max(c*client_num,1)\n",
    "test_acc_target = 0.97  # when to stop the iteration\n",
    "lr = 0.5\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_IID(client_number, seed)\n",
    "test_dataloader = DataLoader(test_dataset, 128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(global_net, train_dataloader, E, lr,device=torch.device(\"cpu:0\")):\n",
    "    \"\"\"\n",
    "        return net, loss, acc\n",
    "    \"\"\"\n",
    "    # deep copy global_net\n",
    "    local_net = deepcopy(global_net)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.SGD(local_net.parameters(), lr,weight_decay=0.01) # 过拟合\n",
    "    accumulator = d2l.Accumulator(3)\n",
    "    for e in range(E):  # epoch E\n",
    "        for x, y in train_dataloader:  # batch size B\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            y_hat = local_net(x)\n",
    "            loss = loss_function(y_hat, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "            \n",
    "    return local_net,accumulator[0] / accumulator[2], accumulator[1]/accumulator[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def now_str():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_writer(*tags):\n",
    "    path = 'logs'\n",
    "    for tag in tags:\n",
    "        path = join(path, tag)\n",
    "    log_dir = join(path, now_str())\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    return writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IID_train(C_list, E,B, lr, seed, train_dataloaders, test_dataloader, test_acc_target, client_number,device):\n",
    "    for C in C_list:\n",
    "        writer = get_writer('MNIST_2NN', 'IID', f'B={B}', f'C={C}')\n",
    "        global_net = MNIST_2NN()\n",
    "        global_net.init_params(seed)\n",
    "        global_net.to(device)\n",
    "        step = 0\n",
    "        test_acc = 0\n",
    "        while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "            m = max(int(C*client_number), 1)\n",
    "            client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "            client_nets = []  # store net(t+1,client_index) by local update\n",
    "            train_loss = []\n",
    "            accumulater = d2l.Accumulator(3)\n",
    "            for client_index in client_indexs:\n",
    "                client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "                client_nets.append(client_net)\n",
    "                length = len(train_dataloaders[client_index]) # example number\n",
    "                accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "            global_net_zero(global_net)  # make global net params all zero\n",
    "            n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "            for client_index in client_indexs:\n",
    "                n += len(train_datasets[client_index]) # example number\n",
    "            for client_index in client_indexs:  # update global net\n",
    "                update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "            # check whether test acc reach the target\n",
    "            test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "            step += 1\n",
    "            \n",
    "            writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "            writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "            writer.add_scalar(\"test acc\", test_acc, step)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10  # batch size for all clients\n",
    "# 加载数据，当B变化时，数据不同\n",
    "train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                shuffle=False) for train_dataset in train_datasets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 # 如果太高，容易过拟合"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in C_list:\n",
    "    writer = get_writer('MNIST_2NN', 'IID', f'B={B}', f'C={C}')\n",
    "    global_net = MNIST_2NN()\n",
    "    global_net.init_params(seed)\n",
    "    step = 0\n",
    "    test_acc = 0\n",
    "    while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "        m = max(int(C*client_number), 1)\n",
    "        client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "        client_nets = []  # store net(t+1,client_index) by local update\n",
    "        accumulater = d2l.Accumulator(3)\n",
    "        for client_index in client_indexs:\n",
    "            client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr)\n",
    "            client_nets.append(client_net)\n",
    "            length = len(train_datasets[client_index]) # example number\n",
    "            accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "        global_net_zero(global_net)  # make global net params all zero\n",
    "        n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "        for client_index in client_indexs:\n",
    "            n += len(train_datasets[client_index])# example number\n",
    "        for client_index in client_indexs:  # update global net\n",
    "            update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "        # check whether test acc reach the target\n",
    "        test_acc = get_test_acc(global_net, test_dataloader)\n",
    "        step += 1\n",
    "        \n",
    "        writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "        writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "        writer.add_scalar(\"test acc\", test_acc, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IID_train(C_list, E,B, lr, seed, train_dataloaders, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     update_global_net(global_net, client_nets[client_indexs\u001b[39m.\u001b[39mindex(client_index)], n, \u001b[39mlen\u001b[39m(train_datasets[client_index]))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# check whether test acc reach the target\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m test_acc \u001b[39m=\u001b[39m get_test_acc(global_net, test_dataloader,device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mtrain loss\u001b[39m\u001b[39m\"\u001b[39m, accumulater[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m accumulater[\u001b[39m2\u001b[39m], step)\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb Cell 44\u001b[0m in \u001b[0;36mget_test_acc\u001b[0;34m(net, test_dataloader, device)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[0;32m---> 94\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[1;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py:269\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, tensor: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    262\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mnormalize(tensor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmean, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py:360\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(tensor, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    358\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be Tensor Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(tensor)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m \u001b[39mreturn\u001b[39;00m F_t\u001b[39m.\u001b[39;49mnormalize(tensor, mean\u001b[39m=\u001b[39;49mmean, std\u001b[39m=\u001b[39;49mstd, inplace\u001b[39m=\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:953\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    951\u001b[0m mean \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(mean, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    952\u001b[0m std \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(std, dtype\u001b[39m=\u001b[39mdtype, device\u001b[39m=\u001b[39mtensor\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 953\u001b[0m \u001b[39mif\u001b[39;00m (std \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49many():\n\u001b[1;32m    954\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstd evaluated to zero after conversion to \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m}\u001b[39;00m\u001b[39m, leading to division by zero.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m mean\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for C in C_list:\n",
    "    writer = get_writer('MNIST_2NN', 'IID', f'B={B}', f'C={C}')\n",
    "    global_net = MNIST_2NN()\n",
    "    global_net.init_params(seed)\n",
    "    global_net.to(device)\n",
    "    step = 0\n",
    "    test_acc = 0\n",
    "    while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "        m = max(int(C*client_number), 1)\n",
    "        client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "        client_nets = []  # store net(t+1,client_index) by local update\n",
    "        accumulater = d2l.Accumulator(3)\n",
    "        for client_index in client_indexs:\n",
    "            client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "            client_nets.append(client_net)\n",
    "            length = len(train_datasets[client_index]) # example number\n",
    "            accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "        global_net_zero(global_net)  # make global net params all zero\n",
    "        n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "        for client_index in client_indexs:\n",
    "            n += len(train_datasets[client_index]) # example number\n",
    "        for client_index in client_indexs:  # update global net\n",
    "            update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "        # check whether test acc reach the target\n",
    "        test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "        step += 1\n",
    "        \n",
    "        writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "        writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "        writer.add_scalar(\"test acc\", test_acc, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m IID_train(C_list, E,B, lr, seed, train_dataloaders, test_dataloader, test_acc_target, client_number,device)\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb Cell 45\u001b[0m in \u001b[0;36mIID_train\u001b[0;34m(C_list, E, B, lr, seed, train_dataloaders, test_dataloader, test_acc_target, client_number, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m accumulater \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mAccumulator(\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m client_index \u001b[39min\u001b[39;00m client_indexs:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     client_net,train_loss,train_acc \u001b[39m=\u001b[39m client_update(global_net, train_dataloaders[client_index], E, lr,device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     client_nets\u001b[39m.\u001b[39mappend(client_net)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_dataloaders[client_index]) \u001b[39m# example number\u001b[39;00m\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb Cell 45\u001b[0m in \u001b[0;36mclient_update\u001b[0;34m(global_net, train_dataloader, E, lr, device)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    return net, loss, acc\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# deep copy global_net\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m local_net \u001b[39m=\u001b[39m deepcopy(global_net)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m loss_function \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m optim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(local_net\u001b[39m.\u001b[39mparameters(), lr,weight_decay\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m) \u001b[39m# 过拟合\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:296\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dictiter:\n\u001b[1;32m    295\u001b[0m         key \u001b[39m=\u001b[39m deepcopy(key, memo)\n\u001b[0;32m--> 296\u001b[0m         value \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    297\u001b[0m         y[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 270\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    271\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    272\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    228\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    229\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/copy.py:137\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mif\u001b[39;00m memo \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     memo \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 137\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mid\u001b[39;49m(x)\n\u001b[1;32m    138\u001b[0m y \u001b[39m=\u001b[39m memo\u001b[39m.\u001b[39mget(d, _nil)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _nil:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IID_train(C_list, E,B, lr, seed, train_dataloaders, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B = inf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 'inf'  # batch size for all clients\n",
    "# 加载数据，当B变化时，数据不同\n",
    "train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                shuffle=False) for train_dataset in train_datasets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01 # 学习率过高，容易过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb Cell 51\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     update_global_net(global_net, client_nets[client_indexs\u001b[39m.\u001b[39mindex(client_index)], n, \u001b[39mlen\u001b[39m(train_datasets[client_index]))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# check whether test acc reach the target\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m test_acc \u001b[39m=\u001b[39m get_test_acc(global_net, test_dataloader,device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mtrain loss\u001b[39m\u001b[39m\"\u001b[39m, accumulater[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m accumulater[\u001b[39m2\u001b[39m], step)\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb Cell 51\u001b[0m in \u001b[0;36mget_test_acc\u001b[0;34m(net, test_dataloader, device)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m test_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_6.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img\u001b[39m.\u001b[39;49mnumpy(), mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py:2974\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2972\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n\u001b[0;32m-> 2974\u001b[0m \u001b[39mreturn\u001b[39;00m frombuffer(mode, size, obj, \u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m, rawmode, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py:2892\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2890\u001b[0m     args \u001b[39m=\u001b[39m mode, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m\n\u001b[1;32m   2891\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m _MAPMODES:\n\u001b[0;32m-> 2892\u001b[0m     im \u001b[39m=\u001b[39m new(mode, (\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m   2893\u001b[0m     im \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39m_new(core\u001b[39m.\u001b[39mmap_buffer(data, size, decoder_name, \u001b[39m0\u001b[39m, args))\n\u001b[1;32m   2894\u001b[0m     \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PIL/Image.py:2806\u001b[0m, in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2804\u001b[0m     im\u001b[39m.\u001b[39mpalette \u001b[39m=\u001b[39m ImagePalette\u001b[39m.\u001b[39mImagePalette()\n\u001b[1;32m   2805\u001b[0m     color \u001b[39m=\u001b[39m im\u001b[39m.\u001b[39mpalette\u001b[39m.\u001b[39mgetcolor(color)\n\u001b[0;32m-> 2806\u001b[0m \u001b[39mreturn\u001b[39;00m im\u001b[39m.\u001b[39m_new(core\u001b[39m.\u001b[39;49mfill(mode, size, color))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for C in C_list:\n",
    "    writer = get_writer('MNIST_2NN', 'IID', f'B={B}', f'C={C}')\n",
    "    global_net = MNIST_2NN()\n",
    "    global_net.init_params(seed)\n",
    "    global_net.to(device)\n",
    "    step = 0\n",
    "    test_acc = 0\n",
    "    while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "        m = max(int(C*client_number), 1)\n",
    "        client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "        client_nets = []  # store net(t+1,client_index) by local update\n",
    "        accumulater = d2l.Accumulator(3)\n",
    "        for client_index in client_indexs:\n",
    "            client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "            client_nets.append(client_net)\n",
    "            length = len(train_datasets[client_index]) # example number\n",
    "            accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "        global_net_zero(global_net)  # make global net params all zero\n",
    "        n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "        for client_index in client_indexs:\n",
    "            n += len(train_datasets[client_index]) # example number\n",
    "        for client_index in client_indexs:  # update global net\n",
    "            update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "        # check whether test acc reach the target\n",
    "        test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "        step += 1\n",
    "        \n",
    "        writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "        writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "        writer.add_scalar(\"test acc\", test_acc, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IID_train(C_list, E,B, lr, seed, train_dataloaders, test_dataloader, test_acc_target, client_number,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
