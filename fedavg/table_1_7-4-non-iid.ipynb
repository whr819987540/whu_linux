{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/whr-pc-ubuntu/.local/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchsummary\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "client_number = 100\n",
    "seed = 0\n",
    "B = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_IID(client_number, seed):\n",
    "    # shuffle,fix the seed\n",
    "    # 100 clients, each 100 examples\n",
    "    dataset_path = \"/home/whr-pc-ubuntu/code/dataset\"\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081)), # 归一化，有利于训练\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path, True, transform, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path, False, transform, download=True)\n",
    "\n",
    "    slice_num = int(len(train_dataset) / client_number)\n",
    "    split_list = [slice_num]*(client_number-1)\n",
    "    split_list.append(len(train_dataset)-sum(split_list))\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_datasets = random_split(train_dataset, split_list)\n",
    "\n",
    "    return train_datasets, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_IID(client_number, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "4\n",
      "0\n",
      "6\n",
      "8\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "1\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "1\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "2\n",
      "1\n",
      "0\n",
      "7\n",
      "9\n",
      "2\n",
      "6\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "1\n",
      "9\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "6\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "8\n",
      "5\n",
      "0\n",
      "2\n",
      "7\n",
      "2\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "0\n",
      "2\n",
      "9\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "1\n",
      "8\n",
      "8\n",
      "7\n",
      "6\n",
      "2\n",
      "0\n",
      "7\n",
      "3\n",
      "9\n",
      "2\n",
      "1\n",
      "4\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "0\n",
      "7\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "9\n",
      "7\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "4\n",
      "7\n",
      "7\n",
      "2\n",
      "8\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "8\n",
      "9\n",
      "9\n",
      "7\n",
      "6\n",
      "3\n",
      "9\n",
      "3\n",
      "4\n",
      "0\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "9\n",
      "1\n",
      "6\n",
      "4\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "8\n",
      "8\n",
      "9\n",
      "6\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "1\n",
      "7\n",
      "8\n",
      "7\n",
      "2\n",
      "1\n",
      "4\n",
      "6\n",
      "1\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "9\n",
      "3\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "7\n",
      "2\n",
      "8\n",
      "1\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "7\n",
      "0\n",
      "8\n",
      "7\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "5\n",
      "7\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "8\n",
      "0\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "9\n",
      "7\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "8\n",
      "7\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "2\n",
      "8\n",
      "1\n",
      "2\n",
      "7\n",
      "3\n",
      "5\n",
      "9\n",
      "1\n",
      "8\n",
      "2\n",
      "5\n",
      "8\n",
      "5\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "8\n",
      "3\n",
      "6\n",
      "9\n",
      "8\n",
      "2\n",
      "0\n",
      "9\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "9\n",
      "6\n",
      "1\n",
      "5\n",
      "8\n",
      "1\n",
      "7\n",
      "3\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "5\n",
      "0\n",
      "9\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "9\n",
      "3\n",
      "3\n",
      "7\n",
      "9\n",
      "2\n",
      "4\n",
      "3\n",
      "8\n",
      "8\n",
      "1\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "9\n",
      "0\n",
      "3\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "9\n",
      "3\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "9\n",
      "0\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "3\n",
      "8\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "5\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "7\n",
      "9\n",
      "9\n",
      "0\n",
      "0\n",
      "7\n",
      "4\n",
      "3\n",
      "9\n",
      "7\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "1\n",
      "7\n",
      "0\n",
      "2\n",
      "9\n",
      "1\n",
      "1\n",
      "7\n",
      "7\n",
      "0\n",
      "1\n",
      "9\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "9\n",
      "3\n",
      "4\n",
      "0\n",
      "7\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "5\n",
      "9\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "9\n",
      "4\n",
      "4\n",
      "3\n",
      "7\n",
      "0\n",
      "9\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "6\n",
      "6\n",
      "9\n",
      "4\n",
      "0\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "5\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "9\n",
      "4\n",
      "2\n",
      "9\n",
      "6\n",
      "1\n",
      "8\n",
      "1\n",
      "3\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "1\n",
      "4\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "9\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "4\n",
      "8\n",
      "5\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in train_datasets[0]:\n",
    "    print(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_Non_IDD(client_number):\n",
    "    # short by digit label, ascending\n",
    "    # 200 shards, each 300 examples\n",
    "    # 100 clients, each 2 shards\n",
    "    # that is, 100 clients, each 600 examples\n",
    "    dataset_path = \"/home/whr-pc-ubuntu/code/dataset\"\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path, True, transform, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path, False, transform, download=True)\n",
    "\n",
    "    # before = [i[1]for i in train_dataset]\n",
    "    # print(before)\n",
    "    train_dataset = sorted(train_dataset, key=lambda x: x[1])\n",
    "    # after = [i[1] for i in train_dataset]\n",
    "    # print(after)\n",
    "\n",
    "    slice_num = int(len(train_dataset) / client_number)\n",
    "    train_datasets = []\n",
    "    for i in range(client_number-1):\n",
    "        train_datasets.append(train_dataset[i*slice_num:(i+1)*slice_num])\n",
    "    train_datasets.append(train_dataset[(client_number-1)*slice_num:])\n",
    "\n",
    "    return train_datasets, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_Non_IDD(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in train_datasets[0]:\n",
    "    print(i[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST_2NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MNIST_2NN(torch.nn.Module):\n",
    "    def __init__(self,dropout_1=0.5,dropout_2=0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.dropout_1_p,self.dropout_2_p = dropout_1,dropout_2\n",
    "        # 输入：784\n",
    "        # 隐藏层 1：784*200，200\n",
    "        # 隐藏层 2：200*200，200\n",
    "        # 输出：200*10,10\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.fc_1 = torch.nn.Linear(784, 200)\n",
    "        self.fc_2 = torch.nn.Linear(200, 200)\n",
    "        self.fc_3 = torch.nn.Linear(200, 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout_1 = torch.nn.Dropout(self.dropout_1_p)\n",
    "        self.dropout_2 = torch.nn.Dropout(self.dropout_2_p)\n",
    "\n",
    "    def init_params(self, seed):\n",
    "        set_seed(seed)\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                # 参数初始化方法一般与激活函数有关\n",
    "                # Relu-kaming\n",
    "                # sigmoid-xavier\n",
    "                nn.init.kaiming_normal_(layer.weight.data)\n",
    "                nn.init.zeros_(layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.training: # 训练模式\n",
    "            x = self.dropout_1(x)  # 过拟合\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu(x)\n",
    "        if self.training: # 训练模式\n",
    "            x = self.dropout_2(x)  # 过拟合\n",
    "        x = self.fc_3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def update_global_net(global_net, local_net, global_num, local_num):\n",
    "    index = 1.0 * local_num / global_num\n",
    "    optim_1 = torch.optim.SGD(global_net.parameters(), 0.1)  # whatever the lr is\n",
    "    optim_2 = torch.optim.SGD(local_net.parameters(), 0.1)  # whatever the lr is\n",
    "\n",
    "    for param_1, param_2 in zip(optim_1.param_groups[0]['params'], optim_2.param_groups[0]['params']):\n",
    "        param_1.data = param_1.data + index * param_2.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def global_net_zero(global_net):\n",
    "    optim = torch.optim.SGD(global_net.parameters(), 0.1)  # whatever the lr is\n",
    "\n",
    "    for param in optim.param_groups[0]['params']:\n",
    "        param.data.zero_()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算 test acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_acc(net,test_dataloader,device=torch.device(\"cpu:0\")):\n",
    "    net.eval() # evaluation mode, don't use the dropout layer\n",
    "    with torch.no_grad():\n",
    "        sum = 0\n",
    "        for x,y in test_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_hat = net(x)\n",
    "            sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "    return 1.0 * sum / len(test_dataset)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0968"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MNIST_2NN()\n",
    "net.init_params(seed)\n",
    "get_test_acc(net, test_dataloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST_2NN exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0  # to initialize the global net\n",
    "E = 1  # epoch\n",
    "client_number = 100  # client_number\n",
    "C_list = [0, 0.1, 0.2, 0.5, 1.0]  # m=max(c*client_num,1)\n",
    "test_acc_target = 0.96  # when to stop the iteration\n",
    "lr = 0.01\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def client_update(global_net, train_dataloader, E, lr,device=torch.device(\"cpu:0\")):\n",
    "    \"\"\"\n",
    "        return net, loss, acc\n",
    "    \"\"\"\n",
    "    # deep copy global_net\n",
    "    local_net = deepcopy(global_net)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.SGD(local_net.parameters(), lr,weight_decay=0.01) # 过拟合\n",
    "    accumulator = d2l.Accumulator(3)\n",
    "\n",
    "    local_net.train()\n",
    "    for e in range(E):  # epoch E\n",
    "        for x, y in train_dataloader:  # batch size B\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            y_hat = local_net(x)\n",
    "            loss = loss_function(y_hat, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "            \n",
    "    return local_net,accumulator[0] / accumulator[2], accumulator[1]/accumulator[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def now_str():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_writer(*tags):\n",
    "    path = 'logs'\n",
    "    for tag in tags:\n",
    "        path = join(path, tag)\n",
    "    writer = SummaryWriter(path)\n",
    "    return writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device):\n",
    "    # 加载数据，当B变化时，数据不同\n",
    "    train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                    shuffle=False) for train_dataset in train_datasets]\n",
    "    now_time = now_str()\n",
    "    for C in C_list:\n",
    "        writer = get_writer('MNIST_2NN', 'IID',f'test_acc={test_acc_target},lr={lr}',f'B={B}', now_time , f'C={C}') # divided by the start-running time\n",
    "        global_net = MNIST_2NN()\n",
    "        global_net.init_params(seed)\n",
    "        global_net.to(device)\n",
    "        step = 0\n",
    "        test_acc = 0\n",
    "        while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "            m = max(int(C*client_number), 1)\n",
    "            client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "            client_nets = []  # store net(t+1,client_index) by local update\n",
    "            accumulater = d2l.Accumulator(3)\n",
    "            for client_index in client_indexs:\n",
    "                client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "                client_nets.append(client_net)\n",
    "                length = len(train_datasets[client_index]) # example number\n",
    "                accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "            global_net_zero(global_net)  # make global net's params all zero\n",
    "            n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "            for client_index in client_indexs:\n",
    "                n += len(train_datasets[client_index]) # example number\n",
    "            for client_index in client_indexs:  # update global net\n",
    "                update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "            # check whether test acc reach the target\n",
    "            test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "            step += 1\n",
    "            \n",
    "            writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "            writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "            writer.add_scalar(\"test acc\", test_acc, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_IID(client_number, seed)\n",
    "test_dataloader = DataLoader(test_dataset, 128, shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 10  # batch size for all clients\n",
    "lr = 0.01 # 如果太高，容易过拟合, test acc降不下来\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb Cell 37\u001b[0m in \u001b[0;36mIID_train\u001b[0;34m(C_list, E, B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m accumulater \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mAccumulator(\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m client_index \u001b[39min\u001b[39;00m client_indexs:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     client_net,train_loss,train_acc \u001b[39m=\u001b[39m client_update(global_net, train_dataloaders[client_index], E, lr,device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     client_nets\u001b[39m.\u001b[39mappend(client_net)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_datasets[client_index]) \u001b[39m# example number\u001b[39;00m\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb Cell 37\u001b[0m in \u001b[0;36mclient_update\u001b[0;34m(global_net, train_dataloader, E, lr, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m y_hat \u001b[39m=\u001b[39m local_net(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(y_hat, y)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m accumulator\u001b[39m.\u001b[39madd(loss\u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],d2l\u001b[39m.\u001b[39maccuracy(y_hat,y),x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B = inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 'inf'  # batch size for all clients\n",
    "lr = 0.01 # 学习率过高，容易过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-IID\n",
    "\n",
    "IID和Non-IID 只是加载的数据源不同, 训练方式完全相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device):\n",
    "    # 加载数据，当B变化时，数据不同\n",
    "    train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                    shuffle=False) for train_dataset in train_datasets]\n",
    "\n",
    "    now_time = now_str()\n",
    "    for C in C_list:\n",
    "        writer = get_writer('MNIST_2NN', 'Non-IID',f'test_acc={test_acc_target},lr={lr}', f'B={B}',now_time , f'C={C}') # divided by the start-running time\n",
    "        global_net = MNIST_2NN()\n",
    "        global_net.init_params(seed)\n",
    "        global_net.to(device)\n",
    "        step = 0\n",
    "        test_acc = 0\n",
    "        while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "            m = max(int(C*client_number), 1)\n",
    "            client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "            client_nets = []  # store net(t+1,client_index) by local update\n",
    "            accumulater = d2l.Accumulator(3)\n",
    "            for client_index in client_indexs:\n",
    "                client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "                client_nets.append(client_net)\n",
    "                length = len(train_datasets[client_index]) # example number\n",
    "                accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "            global_net_zero(global_net)  # make global net's params all zero\n",
    "            n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "            for client_index in client_indexs:\n",
    "                n += len(train_datasets[client_index]) # example number\n",
    "            for client_index in client_indexs:  # update global net\n",
    "                update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "            # check whether test acc reach the target\n",
    "            test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "            step += 1\n",
    "            \n",
    "            writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "            writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "            writer.add_scalar(\"test acc\", test_acc, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_Non_IDD(client_number)\n",
    "test_dataloader = DataLoader(test_dataset, 128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 10  # batch size for all clients\n",
    "lr = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 'inf'  # batch size for all clients\n",
    "lr=0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
