{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchsummary\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "client_number = 100\n",
    "seed = 0\n",
    "B = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_IID(client_number, seed):\n",
    "    # shuffle,fix the seed\n",
    "    # 100 clients, each 100 examples\n",
    "    dataset_path = \"/home/whr-pc-ubuntu/code/dataset\"\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081)), # 归一化，有利于训练\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path, True, transform, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path, False, transform, download=True)\n",
    "\n",
    "    slice_num = int(len(train_dataset) / client_number)\n",
    "    split_list = [slice_num]*(client_number-1)\n",
    "    split_list.append(len(train_dataset)-sum(split_list))\n",
    "\n",
    "    set_seed(seed)\n",
    "    train_datasets = random_split(train_dataset, split_list)\n",
    "\n",
    "    return train_datasets, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_datasets, test_dataset \u001b[39m=\u001b[39m load_data_IID(client_number, seed)\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb Cell 7\u001b[0m in \u001b[0;36mload_data_IID\u001b[0;34m(client_number, seed)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/whr-pc-ubuntu/code/dataset\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m transform \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mNormalize((\u001b[39m0.1307\u001b[39m,), (\u001b[39m0.3081\u001b[39m)), \u001b[39m# 归一化，有利于训练\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m ])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mMNIST(dataset_path, \u001b[39mTrue\u001b[39;49;00m, transform, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mMNIST(dataset_path, \u001b[39mFalse\u001b[39;00m, transform, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m slice_num \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mlen\u001b[39m(train_dataset) \u001b[39m/\u001b[39m client_number)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:104\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:123\u001b[0m, in \u001b[0;36mMNIST._load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    122\u001b[0m     image_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mt10k\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-images-idx3-ubyte\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 123\u001b[0m     data \u001b[39m=\u001b[39m read_image_file(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_folder, image_file))\n\u001b[1;32m    125\u001b[0m     label_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mt10k\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-labels-idx1-ubyte\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     targets \u001b[39m=\u001b[39m read_label_file(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_folder, label_file))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:544\u001b[0m, in \u001b[0;36mread_image_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_image_file\u001b[39m(path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 544\u001b[0m     x \u001b[39m=\u001b[39m read_sn3_pascalvincent_tensor(path, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    545\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39muint8:\n\u001b[1;32m    546\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx should be of dtype torch.uint8 instead of \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:512\u001b[0m, in \u001b[0;36mread_sn3_pascalvincent_tensor\u001b[0;34m(path, strict)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m# read\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 512\u001b[0m     data \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    513\u001b[0m \u001b[39m# parse\u001b[39;00m\n\u001b[1;32m    514\u001b[0m magic \u001b[39m=\u001b[39m get_int(data[\u001b[39m0\u001b[39m:\u001b[39m4\u001b[39m])\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_datasets, test_dataset = load_data_IID(client_number, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "3\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "4\n",
      "0\n",
      "6\n",
      "8\n",
      "9\n",
      "9\n",
      "3\n",
      "1\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "2\n",
      "1\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "1\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "5\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "7\n",
      "0\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "2\n",
      "1\n",
      "0\n",
      "7\n",
      "9\n",
      "2\n",
      "6\n",
      "8\n",
      "7\n",
      "7\n",
      "2\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "1\n",
      "9\n",
      "3\n",
      "1\n",
      "2\n",
      "4\n",
      "8\n",
      "6\n",
      "5\n",
      "1\n",
      "6\n",
      "5\n",
      "6\n",
      "8\n",
      "8\n",
      "5\n",
      "0\n",
      "2\n",
      "7\n",
      "2\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "2\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "0\n",
      "2\n",
      "9\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "1\n",
      "5\n",
      "5\n",
      "1\n",
      "8\n",
      "8\n",
      "7\n",
      "6\n",
      "2\n",
      "0\n",
      "7\n",
      "3\n",
      "9\n",
      "2\n",
      "1\n",
      "4\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "1\n",
      "3\n",
      "1\n",
      "3\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "0\n",
      "7\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "9\n",
      "7\n",
      "3\n",
      "5\n",
      "2\n",
      "7\n",
      "4\n",
      "7\n",
      "7\n",
      "2\n",
      "8\n",
      "1\n",
      "1\n",
      "1\n",
      "9\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "8\n",
      "9\n",
      "9\n",
      "7\n",
      "6\n",
      "3\n",
      "9\n",
      "3\n",
      "4\n",
      "0\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "9\n",
      "1\n",
      "6\n",
      "4\n",
      "5\n",
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "1\n",
      "4\n",
      "5\n",
      "2\n",
      "1\n",
      "2\n",
      "8\n",
      "8\n",
      "9\n",
      "6\n",
      "9\n",
      "3\n",
      "6\n",
      "3\n",
      "1\n",
      "7\n",
      "8\n",
      "7\n",
      "2\n",
      "1\n",
      "4\n",
      "6\n",
      "1\n",
      "5\n",
      "3\n",
      "1\n",
      "5\n",
      "9\n",
      "3\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "3\n",
      "7\n",
      "2\n",
      "8\n",
      "1\n",
      "7\n",
      "7\n",
      "1\n",
      "7\n",
      "4\n",
      "4\n",
      "1\n",
      "4\n",
      "7\n",
      "0\n",
      "8\n",
      "7\n",
      "4\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "2\n",
      "3\n",
      "2\n",
      "5\n",
      "6\n",
      "8\n",
      "3\n",
      "8\n",
      "9\n",
      "5\n",
      "7\n",
      "2\n",
      "3\n",
      "1\n",
      "3\n",
      "8\n",
      "0\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "9\n",
      "7\n",
      "5\n",
      "4\n",
      "0\n",
      "4\n",
      "8\n",
      "7\n",
      "4\n",
      "3\n",
      "6\n",
      "4\n",
      "1\n",
      "3\n",
      "3\n",
      "3\n",
      "9\n",
      "2\n",
      "8\n",
      "1\n",
      "2\n",
      "7\n",
      "3\n",
      "5\n",
      "9\n",
      "1\n",
      "8\n",
      "2\n",
      "5\n",
      "8\n",
      "5\n",
      "0\n",
      "3\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "8\n",
      "6\n",
      "4\n",
      "8\n",
      "8\n",
      "3\n",
      "6\n",
      "9\n",
      "8\n",
      "2\n",
      "0\n",
      "9\n",
      "1\n",
      "5\n",
      "9\n",
      "2\n",
      "9\n",
      "6\n",
      "1\n",
      "5\n",
      "8\n",
      "1\n",
      "7\n",
      "3\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "5\n",
      "0\n",
      "9\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "9\n",
      "3\n",
      "3\n",
      "7\n",
      "9\n",
      "2\n",
      "4\n",
      "3\n",
      "8\n",
      "8\n",
      "1\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "9\n",
      "0\n",
      "3\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "4\n",
      "4\n",
      "3\n",
      "0\n",
      "1\n",
      "9\n",
      "3\n",
      "1\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "9\n",
      "0\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "3\n",
      "8\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "1\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "5\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "2\n",
      "5\n",
      "7\n",
      "9\n",
      "9\n",
      "0\n",
      "0\n",
      "7\n",
      "4\n",
      "3\n",
      "9\n",
      "7\n",
      "6\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "4\n",
      "5\n",
      "2\n",
      "6\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "5\n",
      "1\n",
      "7\n",
      "0\n",
      "2\n",
      "9\n",
      "1\n",
      "1\n",
      "7\n",
      "7\n",
      "0\n",
      "1\n",
      "9\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "5\n",
      "3\n",
      "2\n",
      "5\n",
      "0\n",
      "9\n",
      "3\n",
      "4\n",
      "0\n",
      "7\n",
      "3\n",
      "0\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "5\n",
      "9\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "1\n",
      "7\n",
      "4\n",
      "9\n",
      "6\n",
      "9\n",
      "4\n",
      "4\n",
      "3\n",
      "7\n",
      "0\n",
      "9\n",
      "1\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "0\n",
      "6\n",
      "6\n",
      "9\n",
      "4\n",
      "0\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "1\n",
      "5\n",
      "1\n",
      "1\n",
      "5\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "3\n",
      "1\n",
      "2\n",
      "1\n",
      "9\n",
      "4\n",
      "2\n",
      "9\n",
      "6\n",
      "1\n",
      "8\n",
      "1\n",
      "3\n",
      "7\n",
      "4\n",
      "8\n",
      "9\n",
      "1\n",
      "1\n",
      "4\n",
      "8\n",
      "0\n",
      "1\n",
      "1\n",
      "4\n",
      "2\n",
      "6\n",
      "4\n",
      "1\n",
      "1\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "3\n",
      "2\n",
      "0\n",
      "2\n",
      "3\n",
      "3\n",
      "0\n",
      "3\n",
      "5\n",
      "0\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n",
      "9\n",
      "0\n",
      "2\n",
      "2\n",
      "5\n",
      "7\n",
      "6\n",
      "4\n",
      "8\n",
      "5\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in train_datasets[0]:\n",
    "    print(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_Non_IDD(client_number):\n",
    "    # short by digit label, ascending\n",
    "    # 200 shards, each 300 examples\n",
    "    # 100 clients, each 2 shards\n",
    "    # that is, 100 clients, each 600 examples\n",
    "    dataset_path = \"/home/whr-pc-ubuntu/code/dataset\"\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.MNIST(dataset_path, True, transform, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(dataset_path, False, transform, download=True)\n",
    "\n",
    "    # before = [i[1]for i in train_dataset]\n",
    "    # print(before)\n",
    "    train_dataset = sorted(train_dataset, key=lambda x: x[1])\n",
    "    # after = [i[1] for i in train_dataset]\n",
    "    # print(after)\n",
    "\n",
    "    slice_num = int(len(train_dataset) / client_number)\n",
    "    train_datasets = []\n",
    "    for i in range(client_number-1):\n",
    "        train_datasets.append(train_dataset[i*slice_num:(i+1)*slice_num])\n",
    "    train_datasets.append(train_dataset[(client_number-1)*slice_num:])\n",
    "\n",
    "    return train_datasets, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_Non_IDD(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets[0][1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in train_datasets[0]:\n",
    "    print(i[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST_2NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MNIST_2NN(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # 输入：784\n",
    "        # 隐藏层 1：784*200，200\n",
    "        # 隐藏层 2：200*200，200\n",
    "        # 输出：200*10,10\n",
    "        self.flat = torch.nn.Flatten()\n",
    "        self.fc_1 = torch.nn.Linear(784, 200)\n",
    "        self.fc_2 = torch.nn.Linear(200, 200)\n",
    "        self.fc_3 = torch.nn.Linear(200, 10)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def init_params(self, seed):\n",
    "        set_seed(seed)\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                # 参数初始化方法一般与激活函数有关\n",
    "                # Relu-kaming\n",
    "                # sigmoid-xavier\n",
    "                nn.init.kaiming_normal_(layer.weight.data)\n",
    "                nn.init.zeros_(layer.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flat(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        if self.training: # 训练模式\n",
    "            x = nn.Dropout(0.5)(x)  # 过拟合\n",
    "        x = self.fc_2(x)\n",
    "        x = self.relu(x)\n",
    "        if self.training: # 训练模式\n",
    "            x = nn.Dropout(0.5)(x)  # 过拟合\n",
    "        x = self.fc_3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class FedAvgCNN(nn.Module):\n",
    "    def __init__(self,dropout=0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.conv2d_1 = nn.Conv2d(1,32,(5,5))\n",
    "        self.max_pool = nn.MaxPool2d((2,2))\n",
    "        self.conv2d_2 = nn.Conv2d(32,64,(5,5))\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc = nn.Linear(1024,512)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.linear = nn.Linear(512,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv2d_1(x) # 32,24,24\n",
    "        x = self.relu(x) # 32,24,24\n",
    "        x = self.max_pool(x) # 32,12,12\n",
    "\n",
    "        x = self.conv2d_2(x) # 32,12,12\n",
    "        x = self.relu(x) # 32,12,12\n",
    "        x = self.max_pool(x) # 32,6,6\n",
    "\n",
    "        x = self.flat(x) # 1152\n",
    "        x = self.fc(x) # 512\n",
    "        x = self.relu(x) # 512\n",
    "        x = self.dropout(x) # 512\n",
    "\n",
    "        x = self.softmax(x) # 512\n",
    "\n",
    "        x = self.linear(x) # 10\n",
    "\n",
    "        return x\n",
    "\n",
    "    def init_params(self, seed):\n",
    "        set_seed(seed)\n",
    "        for layer in self.children():\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "                # 参数初始化方法一般与激活函数有关\n",
    "                # Relu-kaming\n",
    "                # sigmoid-xavier\n",
    "                nn.init.kaiming_normal_(layer.weight.data)\n",
    "                nn.init.zeros_(layer.bias.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# global update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def update_global_net(global_net, local_net, global_num, local_num):\n",
    "    index = 1.0 * local_num / global_num\n",
    "    optim_1 = torch.optim.SGD(global_net.parameters(), 0.1)  # whatever the lr is\n",
    "    optim_2 = torch.optim.SGD(local_net.parameters(), 0.1)  # whatever the lr is\n",
    "\n",
    "    for param_1, param_2 in zip(optim_1.param_groups[0]['params'], optim_2.param_groups[0]['params']):\n",
    "        param_1.data = param_1.data + index * param_2.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def global_net_zero(global_net):\n",
    "    optim = torch.optim.SGD(global_net.parameters(), 0.1)  # whatever the lr is\n",
    "\n",
    "    for param in optim.param_groups[0]['params']:\n",
    "        param.data.zero_()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算 test acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_test_acc(net,test_dataloader,device=torch.device(\"cpu:0\")):\n",
    "    net.eval() # evaluation mode, don't use the dropout layer\n",
    "    with torch.no_grad():\n",
    "        sum = 0\n",
    "        for x,y in test_dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            y_hat = net(x)\n",
    "            sum += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "    return 1.0 * sum / len(test_dataset)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0968"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MNIST_2NN()\n",
    "net.init_params(seed)\n",
    "get_test_acc(net, test_dataloader)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST_2NN exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0  # to initialize the global net\n",
    "E = 1  # epoch\n",
    "client_number = 100  # client_number\n",
    "C_list = [0, 0.1, 0.2, 0.5, 1.0]  # m=max(c*client_num,1)\n",
    "test_acc_target = 0.96  # when to stop the iteration\n",
    "lr = 0.01\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def client_update(global_net, train_dataloader, E, lr,device=torch.device(\"cpu:0\")):\n",
    "    \"\"\"\n",
    "        return net, loss, acc\n",
    "    \"\"\"\n",
    "    # deep copy global_net\n",
    "    local_net = deepcopy(global_net)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.SGD(local_net.parameters(), lr,weight_decay=0.0001,momentum=0.9) # 过拟合\n",
    "    accumulator = d2l.Accumulator(3)\n",
    "\n",
    "    local_net.train()\n",
    "    for e in range(E):  # epoch E\n",
    "        for x, y in train_dataloader:  # batch size B\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            y_hat = local_net(x)\n",
    "            loss = loss_function(y_hat, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            accumulator.add(loss*x.shape[0],d2l.accuracy(y_hat,y),x.shape[0])\n",
    "            \n",
    "    return local_net,accumulator[0] / accumulator[2], accumulator[1]/accumulator[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def now_str():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_writer(*tags):\n",
    "    path = 'logs'\n",
    "    for tag in tags:\n",
    "        path = join(path, tag)\n",
    "    writer = SummaryWriter(path)\n",
    "    return writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device):\n",
    "    # 加载数据，当B变化时，数据不同\n",
    "    train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                    shuffle=False) for train_dataset in train_datasets]\n",
    "    \n",
    "    now_time = now_str()\n",
    "    for C in C_list:\n",
    "        writer = get_writer('MNIST_2NN', 'IID',f'test_acc={test_acc_target},lr={lr}',f'B={B}', now_time , f'C={C}') # divided by the start-running time\n",
    "        global_net = MNIST_2NN()\n",
    "        global_net.init_params(seed)\n",
    "        global_net.to(device)\n",
    "        step = 0\n",
    "        test_acc = 0\n",
    "        while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "            m = max(int(C*client_number), 1)\n",
    "            client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "            client_nets = []  # store net(t+1,client_index) by local update\n",
    "            accumulater = d2l.Accumulator(3)\n",
    "            for client_index in client_indexs:\n",
    "                client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "                client_nets.append(client_net)\n",
    "                length = len(train_datasets[client_index]) # example number\n",
    "                accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "            global_net_zero(global_net)  # make global net's params all zero\n",
    "            n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "            for client_index in client_indexs:\n",
    "                n += len(train_datasets[client_index]) # example number\n",
    "            for client_index in client_indexs:  # update global net\n",
    "                update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "            # check whether test acc reach the target\n",
    "            test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "            step += 1\n",
    "            \n",
    "            writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "            writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "            writer.add_scalar(\"test acc\", test_acc, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_IID(client_number, seed)\n",
    "test_dataloader = DataLoader(test_dataset, 128, shuffle=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 10  # batch size for all clients\n",
    "lr = 0.01 # 如果太高，容易过拟合, test acc降不下来\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb Cell 37\u001b[0m in \u001b[0;36mIID_train\u001b[0;34m(C_list, E, B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m accumulater \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mAccumulator(\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m client_index \u001b[39min\u001b[39;00m client_indexs:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     client_net,train_loss,train_acc \u001b[39m=\u001b[39m client_update(global_net, train_dataloaders[client_index], E, lr,device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     client_nets\u001b[39m.\u001b[39mappend(client_net)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_datasets[client_index]) \u001b[39m# example number\u001b[39;00m\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb Cell 37\u001b[0m in \u001b[0;36mclient_update\u001b[0;34m(global_net, train_dataloader, E, lr, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m y_hat \u001b[39m=\u001b[39m local_net(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(y_hat, y)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m optim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_7-4.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m accumulator\u001b[39m.\u001b[39madd(loss\u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],d2l\u001b[39m.\u001b[39maccuracy(y_hat,y),x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B = inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 'inf'  # batch size for all clients\n",
    "lr = 0.01 # 学习率过高，容易过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-IID\n",
    "\n",
    "IID和Non-IID 只是加载的数据源不同, 训练方式完全相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device):\n",
    "    # 加载数据，当B变化时，数据不同\n",
    "    train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                    shuffle=False) for train_dataset in train_datasets]\n",
    "\n",
    "    now_time = now_str()\n",
    "    for C in C_list:\n",
    "        writer = get_writer('MNIST_2NN', 'Non-IID',f'test_acc={test_acc_target},lr={lr}', f'B={B}',now_time , f'C={C}') # divided by the start-running time\n",
    "        global_net = MNIST_2NN()\n",
    "        global_net.init_params(seed)\n",
    "        global_net.to(device)\n",
    "        step = 0\n",
    "        test_acc = 0\n",
    "        while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "            m = max(int(C*client_number), 1)\n",
    "            client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "            client_nets = []  # store net(t+1,client_index) by local update\n",
    "            accumulater = d2l.Accumulator(3)\n",
    "            for client_index in client_indexs:\n",
    "                client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "                client_nets.append(client_net)\n",
    "                length = len(train_datasets[client_index]) # example number\n",
    "                accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "            global_net_zero(global_net)  # make global net's params all zero\n",
    "            n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "            for client_index in client_indexs:\n",
    "                n += len(train_datasets[client_index]) # example number\n",
    "            for client_index in client_indexs:  # update global net\n",
    "                update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "            # check whether test acc reach the target\n",
    "            test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "            step += 1\n",
    "            \n",
    "            writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "            writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "            writer.add_scalar(\"test acc\", test_acc, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_Non_IDD(client_number)\n",
    "test_dataloader = DataLoader(test_dataset, 128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 10  # batch size for all clients\n",
    "lr = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 'inf'  # batch size for all clients\n",
    "lr=0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "seed = 0  # to initialize the global net\n",
    "E = 5  # epoch\n",
    "client_number = 100  # client_number\n",
    "# C_list = [0, 0.1, 0.2, 0.5, 1.0]  # m=max(c*client_num,1)\n",
    "C_list = [0.5, 1.0]  # m=max(c*client_num,1)\n",
    "test_acc_target = 0.99  # when to stop the iteration\n",
    "lr = 0.0001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_IID(client_number, seed)\n",
    "test_dataloader = DataLoader(test_dataset, 128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def CNN_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device):\n",
    "    # 加载数据，当B变化时，数据不同\n",
    "    train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                    shuffle=False) for train_dataset in train_datasets]\n",
    "\n",
    "    now_time = now_str()\n",
    "    for C in C_list:\n",
    "        writer = get_writer('FedAvgCNN', 'IID',f'test_acc={test_acc_target},lr={lr}',f'B={B}', now_time , f'C={C}') # divided by the start-running time\n",
    "        global_net = FedAvgCNN()\n",
    "        global_net.init_params(seed)\n",
    "        global_net.to(device)\n",
    "        step = 0\n",
    "        test_acc = 0\n",
    "        while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "            m = max(int(C*client_number), 1)\n",
    "            client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "            client_nets = []  # store net(t+1,client_index) by local update\n",
    "            accumulater = d2l.Accumulator(3)\n",
    "            for client_index in client_indexs:\n",
    "                client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "                client_nets.append(client_net)\n",
    "                length = len(train_datasets[client_index]) # example number\n",
    "                accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "            global_net_zero(global_net)  # make global net's params all zero\n",
    "            n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "            for client_index in client_indexs:\n",
    "                n += len(train_datasets[client_index]) # example number\n",
    "            for client_index in client_indexs:  # update global net\n",
    "                update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "            # check whether test acc reach the target\n",
    "            test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "            step += 1\n",
    "            \n",
    "            writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "            writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "            writer.add_scalar(\"test acc\", test_acc, step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 10  # batch size for all clients\n",
    "lr = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107917/1032299554.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x) # 512\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.76 GiB total capacity; 222.18 MiB already allocated; 5.86 GiB free; 226.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb Cell 62\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m CNN_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb Cell 62\u001b[0m in \u001b[0;36mCNN_IID_train\u001b[0;34m(C_list, E, B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m accumulater \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mAccumulator(\u001b[39m3\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfor\u001b[39;00m client_index \u001b[39min\u001b[39;00m client_indexs:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     client_net,train_loss,train_acc \u001b[39m=\u001b[39m client_update(global_net, train_dataloaders[client_index], E, lr,device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     client_nets\u001b[39m.\u001b[39mappend(client_net)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     length \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_datasets[client_index]) \u001b[39m# example number\u001b[39;00m\n",
      "\u001b[1;32m/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb Cell 62\u001b[0m in \u001b[0;36mclient_update\u001b[0;34m(global_net, train_dataloader, E, lr, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m         loss \u001b[39m=\u001b[39m loss_function(y_hat, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m         optim\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m         accumulator\u001b[39m.\u001b[39madd(loss\u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],d2l\u001b[39m.\u001b[39maccuracy(y_hat,y),x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3060ti/home/whr-pc-ubuntu/code/fedavg/table_1_8-1-2.ipynb#Y114sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mreturn\u001b[39;00m local_net,accumulator[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m accumulator[\u001b[39m2\u001b[39m], accumulator[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39maccumulator[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/optim/sgd.py:151\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 151\u001b[0m sgd(params_with_grad,\n\u001b[1;32m    152\u001b[0m     d_p_list,\n\u001b[1;32m    153\u001b[0m     momentum_buffer_list,\n\u001b[1;32m    154\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    160\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    161\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    163\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/optim/sgd.py:202\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 202\u001b[0m func(params,\n\u001b[1;32m    203\u001b[0m      d_p_list,\n\u001b[1;32m    204\u001b[0m      momentum_buffer_list,\n\u001b[1;32m    205\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    206\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    207\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    208\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    209\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    210\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    211\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
      "File \u001b[0;32m~/.conda/envs/whr/lib/python3.8/site-packages/torch/optim/sgd.py:235\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    232\u001b[0m buf \u001b[39m=\u001b[39m momentum_buffer_list[i]\n\u001b[1;32m    234\u001b[0m \u001b[39mif\u001b[39;00m buf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     buf \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mclone(d_p)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m    236\u001b[0m     momentum_buffer_list[i] \u001b[39m=\u001b[39m buf\n\u001b[1;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.76 GiB total capacity; 222.18 MiB already allocated; 5.86 GiB free; 226.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "CNN_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 'inf'  # batch size for all clients\n",
    "lr = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CNN_IID_train(C_list, E,B, lr, seed, train_datasets ,test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def CNN_Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device):\n",
    "    # 加载数据，当B变化时，数据不同\n",
    "    train_dataloaders = [DataLoader(train_dataset, len(train_dataset) if B == 'inf' else B,\n",
    "                                    shuffle=False) for train_dataset in train_datasets]\n",
    "\n",
    "    now_time = now_str()\n",
    "    for C in C_list:\n",
    "        writer = get_writer('FedAvgCNN', 'Non-IID',f'test_acc={test_acc_target},lr={lr}', f'B={B}',now_time , f'C={C}') # divided by the start-running time\n",
    "        global_net = FedAvgCNN()\n",
    "        global_net.init_params(seed)\n",
    "        global_net.to(device)\n",
    "        step = 0\n",
    "        test_acc = 0\n",
    "        while test_acc < test_acc_target:  # control the variable t by the acc target\n",
    "            m = max(int(C*client_number), 1)\n",
    "            client_indexs = random.sample(range(0, client_number), m)  # select m clients randomly\n",
    "\n",
    "            client_nets = []  # store net(t+1,client_index) by local update\n",
    "            accumulater = d2l.Accumulator(3)\n",
    "            for client_index in client_indexs:\n",
    "                client_net,train_loss,train_acc = client_update(global_net, train_dataloaders[client_index], E, lr,device)\n",
    "                client_nets.append(client_net)\n",
    "                length = len(train_datasets[client_index]) # example number\n",
    "                accumulater.add(train_loss*length,train_acc*length,length)\n",
    "\n",
    "            global_net_zero(global_net)  # make global net's params all zero\n",
    "            n = 0 # get n. n should be the sum of examples in variable client_nets, not 60000\n",
    "            for client_index in client_indexs:\n",
    "                n += len(train_datasets[client_index]) # example number\n",
    "            for client_index in client_indexs:  # update global net\n",
    "                update_global_net(global_net, client_nets[client_indexs.index(client_index)], n, len(train_datasets[client_index]))\n",
    "\n",
    "            # check whether test acc reach the target\n",
    "            test_acc = get_test_acc(global_net, test_dataloader,device)\n",
    "            step += 1\n",
    "            \n",
    "            writer.add_scalar(\"train loss\", accumulater[0] / accumulater[2], step)\n",
    "            writer.add_scalar(\"train acc\", accumulater[1] / accumulater[2], step)\n",
    "            writer.add_scalar(\"test acc\", test_acc, step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_datasets, test_dataset = load_data_Non_IDD(client_number)\n",
    "test_dataloader = DataLoader(test_dataset, 128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 10  # batch size for all clients\n",
    "lr = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CNN_Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B=inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "B = 'inf'  # batch size for all clients\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = d2l.try_gpu()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "CNN_Non_IID_train(C_list, E,B, lr, seed, train_datasets, test_dataloader, test_acc_target, client_number,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
